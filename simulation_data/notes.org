#+TITLE: Key to Simulation Datasets

* rw_2014-12-19
__version__ = '0.3'

numPaths = 50000 # Number of paths per pair of walk parameters
pathLength =  16000 * (random(numPaths) - 0.5) + 25000 # bp in walk
linDensity = arange(10, 110, 20)  # bp / nm
persisLength = arange(10, 210, 20) # nm
segConvFactor = 25 / min(persisLength) # segments / min persisLen
nameDB = 'rw_' + dateStr

tic = time.clock()
myCollector = WLCCollector(numPaths,

			   pathLength,
			   linDensity,
			   persisLength,
			   segConvFactor,
			   nameDB)
toc = time.clock()
print('Total processing time: %f' % (toc - tic))

* rw_2014-12-22
__version__ = '0.4'

This code was used to test the new algorithm, which randomly displaces
the localizations according to a Gaussian distribution.

import matplotlib.pyplot as plt
numPaths = 1000 # Number of paths per pair of walk parameters
pathLength =  16000 * (random(numPaths) - 0.5) + 25000 # bp in walk
linDensity = arange(10, 110, 20)  # bp / nm
persisLength = arange(10, 210, 20) # nm
#linDensity = array([100])
#persisLength = array([100])
segConvFactor = 25 / min(persisLength) # segments / min persisLen
nameDB = 'rw_' + dateStr
locPrecision = 10 # nm

tic = time.clock()
myCollector = WLCCollector(numPaths,
			   pathLength,
			   linDensity,
			   persisLength,
			   segConvFactor,
			   nameDB,
			   locPrecision)
toc = time.clock()
print('Total processing time: %f' % (toc - tic))
    
* rw_2014-12-23
__version__ = '0.4'
Simulate large-scale (poor resolution) map for Hela S

from numpy import ones, append
import matplotlib.pyplot as plt
numPaths = 250000 # Number of paths per pair of walk parameters
pathLength =  5100 * (random(numPaths) - 0.5) + 11750 # bp in walk
linDensity = arange(10, 110, 20)  # bp / nm
persisLength = arange(10, 210, 20) # nm
segConvFactor = 25 / min(persisLength) # segments / min persisLen
nameDB = 'rw_' + dateStr
locPrecision = 2.45 # nm

tic = time.time()
myCollector = WLCCollector(numPaths,
			   pathLength,
			   linDensity,
			   persisLength,
			   segConvFactor,
			   nameDB,
			   locPrecision)
toc = time.time()
print('Total processing time: %f' % (toc - tic))

* rw_2015-1-7
__version__ = '0.5'
Simulate Hela L WT with a medium-resolution of parameters

from numpy import ones, append
kwargs = {}
kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
kwargs['pathLength'] =  13900 * (random(kwargs['numPaths']) - 0.5) + 26250 # bp in walk
#kwargs['pathLength'] = 25000 * ones(kwargs['numPaths'])
kwargs['linDensity'] = arange(20, 70, 10)  # bp / nm
kwargs['persisLength'] = arange(20, 110, 10) # nm
#linDensity = array([100])
#persisLength = array([100])
kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
kwargs['nameDB'] = 'rw_' + dateStr
kwargs['locPrecision'] = 2.12 # nm

tic = time.time()
myCollector = WLCCollector(**kwargs)
toc = time.time()
print('Total processing time: %f' % (toc - tic))
* rw_2015-1-14_HelaL_WT
  Simulation of Hela L untransfected cells with the Southern blot in
  the paper.

  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = arange(10, 110, 20)  # bp / nm
  kwargs['persisLength'] = arange(10, 210, 20) # nm
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))

* rw_2015-1-15_HelaS_WT

Simulation of Hela S untransfected cells with the Southern blot in the
paper.

__version__ = '0.5'
from numpy import ones, append
kwargs = {}
kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
kwargs['linDensity'] =arange(10, 110, 20)  # bp / nm
kwargs['persisLength'] = arange(10, 210, 20) # nm
kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
kwargs['nameDB'] = 'rw_' + dateStr
kwargs['locPrecision'] = 2.45 # nm

* rw_2015-1-15_HelaL_WT
Simulate another section of the parameter grid, zooming in slightly
around the previous Hela L peak.

__version__ = '0.5'
from numpy import ones, append
kwargs = {}
kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
kwargs['linDensity'] = arange(20, 100, 20)  # bp / nm
kwargs['persisLength'] = arange(20, 120, 20) # nm
kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
kwargs['nameDB'] = 'rw_' + dateStr
kwargs['locPrecision'] = 2.12 # nm

* rw_2015-1-16_HelaL_WT
  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = arange(15, 65, 10)  # bp / nm
  kwargs['persisLength'] = arange(15,105 , 10) # nm 
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
*  rw_2015-1-16_HelaS_WT
  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
  #kwargs['pathLength'] = 25000 * ones(kwargs['numPaths'])
  kwargs['linDensity'] = array([5, 15, 20, 25, 35])  # bp / nm
  kwargs['persisLength'] = arange(20, 100, 20) # nm
  #linDensity = array([100])
  #persisLength = array([100])
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.45 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* rw_2015-1-20_HelaL_WT
  Here I'm checking the upper persistence length range of the Hela L
  WT parameter space.
  
  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  #kwargs['pathLength'] = 25000 * ones(kwargs['numPaths'])
  kwargs['linDensity'] = arange(30, 55, 5)  # bp / nm
  kwargs['persisLength'] = arange(100, 210, 10) # nm
  #linDensity = array([100])
  #persisLength = array([100])
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* [#C] rw_2015-1-26_HelaL_WT
  Former primary dataset.
  __version__ = '0.6'
  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 60, 5), arange(10, 105, 5))
  C2, LP2 = meshgrid(arange(30, 65, 5), arange(105, 205, 5))
  C3, LP3 = meshgrid(arange(60, 100, 10), arange(10, 220, 20))
  C4, LP4 = meshgrid(array([20]), arange(110, 210, 20))

  C = concatenate((C1.flatten(), C2.flatten(), C3.flatten(), C4.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten(), LP3.flatten(), LP4.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 10 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* [#C] rw_2015-2-2_HelaS_WT
  Former primary dataset.
  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 55, 5), arange(10, 205, 5))
  C2, LP2 = meshgrid(arange(60, 100, 10), arange(10, 205, 20))

  C = concatenate((C1.flatten(), C2.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 10 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
*  rw_2015-3-7-HelaL_WT
  These are full simulations using the mean localization precision
  from the data.

  __version__ = '0.6'

  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 60, 5), arange(10, 105, 5))
  C2, LP2 = meshgrid(arange(30, 65, 5), arange(105, 205, 5))
  C3, LP3 = meshgrid(arange(60, 100, 10), arange(10, 220, 20))
  C4, LP4 = meshgrid(array([20]), arange(110, 210, 20))

  C = concatenate((C1.flatten(), C2.flatten(), C3.flatten(), C4.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten(), LP3.flatten(), LP4.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))

*  rw_2015-3-7-HelaS_WT
  These are full simulations using the mean localization precision
  from the data.

  __version__ = '0.6'
  
  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 55, 5), arange(10, 205, 5))
  C2, LP2 = meshgrid(arange(60, 100, 10), arange(10, 205, 20))

  C = concatenate((C1.flatten(), C2.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.45 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
*  rw_2015-8-7
  With this I wanted to compare the simulated datasets with 5 nm
  precision to an experimental dataset taken on the HT-STORM
  microscope, which also has a 5 nm precision.
  

 from numpy import ones, append, array, concatenate
 C1, LP1 = meshgrid(arange(10, 55, 5), arange(10, 205, 5))
 C2, LP2 = meshgrid(arange(60, 100, 10), arange(10, 205, 20))

 C = concatenate((C1.flatten(), C2.flatten()))
 LP = concatenate((LP1.flatten(), LP2.flatten()))

 kwargs = {}
 kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
 kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
 kwargs['linDensity'] = C  # bp / nm
 kwargs['persisLength'] = LP # nm
 kwargs['segConvFactor'] = 2.5 # segments / min persisLen
 kwargs['nameDB'] = 'rw_' + dateStr
 kwargs['locPrecision'] = 5 # nm
 kwargs['fullSpecParam'] = True
 
 tic = time.time()
 myCollector = WLCCollector(**kwargs)
 toc = time.time()
 print('Total processing time: %f' % (toc - tic))
*  simData_HelaL_WT_2015-8-14
  Testing new parameters for WT HeLa L dataset for the paper, using
  the correct genomic length distribution and localization precision.

  C1, LP1 = meshgrid(  arange(10, 60, 5),         arange(10, 105, 5))
  C2, LP2 = meshgrid(  arange(30, 65, 5),         arange(105, 205, 5))
  C3, LP3 = meshgrid(arange(60, 100, 10),         arange(10, 220, 20))
  C4, LP4 = meshgrid(        array([20]),         arange(110, 210, 20))

  C = concatenate((C1.flatten(), C2.flatten(),
		   C3.flatten(), C4.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten(),
		    LP3.flatten(), LP4.flatten()))

  # Load the genomic length distribution from the file
  with open('HeLaLGenomicLength.txt', 'r') as genomicLengthsFile:
      genomicLengths = loadtxt(genomicLengthsFile)

  numPaths     = 100000
  basePairDist = genomicLengths[0:numPaths] * 1000 # Convert from kb to bp

  simArgs = {'numPaths'      : numPaths,
	     'pathLength'    : basePairDist,
	     'linDensity'    : C,
	     'persisLength'  : LP,
	     'segConvFactor' : 2.5,
	     'nameDB'        : 'simData_HelaL_WT_' + PolymerPy.dateStr,
	     'locPrecision'  : 15,
	     'fullSpecParam' : True}
*  simData_HelaL_WT_2015-8-17
  This filled in a region that was undersampled in the 2015-8-14
  simulation for HeLa L WT.

  C5, LP5 = meshgrid(arange(65, 105, 10), arange(25, 205, 5))
  C6, LP6 = meshgrid(arange(60, 100, 10), array([25, 35, 40, 45, 55, 60, 65, 75, 80, 85, 95, 100]))
  C7, LP7 = meshgrid(arange(70, 100, 10), array([105, 115, 120, 125, 135, 140, 145, 155, 160, 165, 175, 180, 185, 195, 200, 205]))

  C = concatenate((C5.flatten(),
		   C6.flatten(),
		   C7.flatten()))
  LP = concatenate((LP5.flatten(),
		    LP6.flatten(),
		    LP7.flatten()))

  # Load the genomic length distribution from the file
  with open('HeLaLGenomicLength.txt', 'r') as genomicLengthsFile:
      genomicLengths = loadtxt(genomicLengthsFile)

  numPaths     = 100000
  basePairDist = genomicLengths[0:numPaths] * 1000 # Convert from kb to bp

  simArgs = {'numPaths'      : numPaths,
	     'pathLength'    : basePairDist,
	     'linDensity'    : C,
	     'persisLength'  : LP,
	     'segConvFactor' : 2.5,
	     'nameDB'        : 'simData_HelaL_WT_' + PolymerPy.dateStr,
	     'locPrecision'  : 15,
	     'fullSpecParam' : True}
* [#A] simData_HeLaL_WT_2015-8-19
Primary simulation data for the paper, HeLa L.

from numpy import ones, append, array, concatenate, loadtxt

with open('HeLaLGenomicLength.txt', 'r') as genomicLengthsFile:
    genomicLengths = loadtxt(genomicLengthsFile)

C1, LP1 = meshgrid(  arange(10, 60, 5),         arange(10, 105, 5))
C2, LP2 = meshgrid(  arange(30, 65, 5),         arange(105, 205, 5))
C3, LP3 = meshgrid(arange(60, 100, 10),         arange(10, 220, 20))
C4, LP4 = meshgrid(        array([20]),         arange(110, 210, 20))
C5, LP5 = meshgrid(arange(65, 105, 10), arange(25, 205, 5))
C6, LP6 = meshgrid(arange(60, 100, 10), array([25, 35, 40, 45, 55, 60, 65, 75, 80, 85, 95, 100]))
C7, LP7 = meshgrid(arange(70, 100, 10), array([105, 115, 120, 125, 135, 140, 145, 155, 160, 165, 175, 180, 185, 195, 200, 205]))

C = concatenate((C1.flatten(),
		 C2.flatten(),
		 C3.flatten(),
		 C4.flatten(),
		 C5.flatten(),
		 C6.flatten(),
		 C7.flatten()))
LP = concatenate((LP1.flatten(),
		  LP2.flatten(),
		  LP3.flatten(),
		  LP4.flatten(),
		  LP5.flatten(),
		  LP6.flatten(),
		  LP7.flatten()))

numPaths     = 100000
basePairDist = genomicLengths[0:numPaths] * 1000 # Convert from kb to bp

kwargs = {}
kwargs['numPaths'] = numPaths # Number of paths per pair of walk parameters
kwargs['pathLength'] =  basePairDist # bp in walk
kwargs['linDensity'] = C  # bp / nm
kwargs['persisLength'] = LP # nm 
kwargs['segConvFactor'] = 2.5 # segments / min persisLen
kwargs['nameDB'] = 'simData_HeLaL_WT_' + dateStr
kwargs['locPrecision'] = 15 # nm
kwargs['fullSpecParam'] = True

tic = time.time()
myCollector = WLCCollector(**kwargs)
toc = time.time()
print('Total processing time: %f' % (toc - tic))

* [#A] simData_HeLaS_WT_2015-8-21
Primary simulation data for the paper, HeLa S.

# Define two separate square grids of parameter pair values.
C1, LP1 = meshgrid(  arange(10, 55, 5),  arange(10, 205, 5))
C2, LP2 = meshgrid(arange(60, 100, 10), arange(10, 205, 20))

C  = concatenate(( C1.flatten(),  C2.flatten()))
LP = concatenate((LP1.flatten(), LP2.flatten()))

with open('HeLaSGenomicLength.txt', 'r') as genomicLengthsFile:
    genomicLengths = loadtxt(genomicLengthsFile)
    
numPaths     = 100000
basePairDist = genomicLengths[0:numPaths] * 1000 # Convert from kb to bp

simArgs = {'numPaths'      : numPaths,
           'pathLength'    : basePairDist,
           'linDensity'    : C,
           'persisLength'  : LP,
           'segConvFactor' : 2.5,
           'nameDB'        : 'simData_HelaS_WT_' + PolymerPy.dateStr,
           'locPrecision'  : 15,
           'fullSpecParam' : True}

tic = time.time()

# Unpack the argument dictionary and call the collector.
myCollector = PolymerPy.WLCCollector(**simArgs)
toc = time.time()

print('Total simulation time: %f' % (toc - tic))

* [#B] simData_HeLaL_WT_2015-8-27
HeLa L localization precision test: precision = 10 nm

from numpy import ones, append, array, concatenate, loadtxt

with open('HeLaLGenomicLength.txt', 'r') as genomicLengthsFile:
    genomicLengths = loadtxt(genomicLengthsFile)

C1, LP1 = meshgrid(  arange(10, 60, 5),         arange(10, 105, 5))
C2, LP2 = meshgrid(  arange(30, 65, 5),         arange(105, 205, 5))
C3, LP3 = meshgrid(arange(60, 100, 10),         arange(10, 220, 20))
C4, LP4 = meshgrid(        array([20]),         arange(110, 210, 20))
C5, LP5 = meshgrid(arange(65, 105, 10), arange(25, 205, 5))
C6, LP6 = meshgrid(arange(60, 100, 10), array([25, 35, 40, 45, 55, 60, 65, 75, 80, 85, 95, 100]))
C7, LP7 = meshgrid(arange(70, 100, 10), array([105, 115, 120, 125, 135, 140, 145, 155, 160, 165, 175, 180, 185, 195, 200, 205]))

C = concatenate((C1.flatten(),
		 C2.flatten(),
		 C3.flatten(),
		 C4.flatten(),
		 C5.flatten(),
		 C6.flatten(),
		 C7.flatten()))
LP = concatenate((LP1.flatten(),
		  LP2.flatten(),
		  LP3.flatten(),
		  LP4.flatten(),
		  LP5.flatten(),
		  LP6.flatten(),
		  LP7.flatten()))

numPaths     = 100000
basePairDist = genomicLengths[0:numPaths] * 1000 # Convert from kb to bp

kwargs = {}
kwargs['numPaths'] = numPaths # Number of paths per pair of walk parameters
kwargs['pathLength'] =  basePairDist # bp in walk
kwargs['linDensity'] = C  # bp / nm
kwargs['persisLength'] = LP # nm 
kwargs['segConvFactor'] = 2.5 # segments / min persisLen
kwargs['nameDB'] = 'simData_HeLaL_WT_' + dateStr
kwargs['locPrecision'] = 10 # nm
kwargs['fullSpecParam'] = True

tic = time.time()
myCollector = WLCCollector(**kwargs)
toc = time.time()
print('Total processing time: %f' % (toc - tic))

* [#B] simData_HeLaS_WT_2015-8-28
  HeLa S localization precision test: precision = 10 nm

  with open('HeLaSGenomicLength.txt', 'r') as genomicLengthsFile:
      genomicLengths = loadtxt(genomicLengthsFile)

  numPaths     = 100000
  basePairDist = genomicLengths[0:numPaths] * 1000 # Convert from kb to bp

  simArgs = {'numPaths'      : numPaths,
	     'pathLength'    : basePairDist,
	     'linDensity'    : C,
	     'persisLength'  : LP,
	     'segConvFactor' : 2.5,
	     'nameDB'        : 'simData_HelaS_WT_' + PolymerPy.dateStr,
	     'locPrecision'  : 10,
	     'fullSpecParam' : True}

  tic = time.time()

  # Unpack the argument dictionary and call the collector.
  myCollector = PolymerPy.WLCCollector(**simArgs)
  toc = time.time()


* [#B] simData_HeLaL_WT_2015-8-31
HeLa L localization precision test: precision = 5 nm

from numpy import ones, append, array, concatenate, loadtxt

with open('HeLaLGenomicLength.txt', 'r') as genomicLengthsFile:
    genomicLengths = loadtxt(genomicLengthsFile)

C1, LP1 = meshgrid(  arange(10, 60, 5),         arange(10, 105, 5))
C2, LP2 = meshgrid(  arange(30, 65, 5),         arange(105, 205, 5))
C3, LP3 = meshgrid(arange(60, 100, 10),         arange(10, 220, 20))
C4, LP4 = meshgrid(        array([20]),         arange(110, 210, 20))
C5, LP5 = meshgrid(arange(65, 105, 10), arange(25, 205, 5))
C6, LP6 = meshgrid(arange(60, 100, 10), array([25, 35, 40, 45, 55, 60, 65, 75, 80, 85, 95, 100]))
C7, LP7 = meshgrid(arange(70, 100, 10), array([105, 115, 120, 125, 135, 140, 145, 155, 160, 165, 175, 180, 185, 195, 200, 205]))

C = concatenate((C1.flatten(),
		 C2.flatten(),
		 C3.flatten(),
		 C4.flatten(),
		 C5.flatten(),
		 C6.flatten(),
		 C7.flatten()))
LP = concatenate((LP1.flatten(),
		  LP2.flatten(),
		  LP3.flatten(),
		  LP4.flatten(),
		  LP5.flatten(),
		  LP6.flatten(),
		  LP7.flatten()))

numPaths     = 100000
basePairDist = genomicLengths[0:numPaths] * 1000 # Convert from kb to bp

kwargs = {}
kwargs['numPaths'] = numPaths # Number of paths per pair of walk parameters
kwargs['pathLength'] =  basePairDist # bp in walk
kwargs['linDensity'] = C  # bp / nm
kwargs['persisLength'] = LP # nm 
kwargs['segConvFactor'] = 2.5 # segments / min persisLen
kwargs['nameDB'] = 'simData_HeLaL_WT_' + dateStr
kwargs['locPrecision'] = 10 # nm
kwargs['fullSpecParam'] = True

tic = time.time()
myCollector = WLCCollector(**kwargs)
toc = time.time()
print('Total processing time: %f' % (toc - tic))
