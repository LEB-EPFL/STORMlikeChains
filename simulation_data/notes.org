#+TITLE: Key to Simulation Datasets

* rw_2014-12-19
__version__ = '0.3'

numPaths = 50000 # Number of paths per pair of walk parameters
pathLength =  16000 * (random(numPaths) - 0.5) + 25000 # bp in walk
linDensity = arange(10, 110, 20)  # bp / nm
persisLength = arange(10, 210, 20) # nm
segConvFactor = 25 / min(persisLength) # segments / min persisLen
nameDB = 'rw_' + dateStr

tic = time.clock()
myCollector = WLCCollector(numPaths,

			   pathLength,
			   linDensity,
			   persisLength,
			   segConvFactor,
			   nameDB)
toc = time.clock()
print('Total processing time: %f' % (toc - tic))

* rw_2014-12-22
__version__ = '0.4'

This code was used to test the new algorithm, which randomly displaces
the localizations according to a Gaussian distribution.

import matplotlib.pyplot as plt
numPaths = 1000 # Number of paths per pair of walk parameters
pathLength =  16000 * (random(numPaths) - 0.5) + 25000 # bp in walk
linDensity = arange(10, 110, 20)  # bp / nm
persisLength = arange(10, 210, 20) # nm
#linDensity = array([100])
#persisLength = array([100])
segConvFactor = 25 / min(persisLength) # segments / min persisLen
nameDB = 'rw_' + dateStr
locPrecision = 10 # nm

tic = time.clock()
myCollector = WLCCollector(numPaths,
			   pathLength,
			   linDensity,
			   persisLength,
			   segConvFactor,
			   nameDB,
			   locPrecision)
toc = time.clock()
print('Total processing time: %f' % (toc - tic))
    
* rw_2014-12-23
__version__ = '0.4'
Simulate large-scale (poor resolution) map for Hela S

from numpy import ones, append
import matplotlib.pyplot as plt
numPaths = 250000 # Number of paths per pair of walk parameters
pathLength =  5100 * (random(numPaths) - 0.5) + 11750 # bp in walk
linDensity = arange(10, 110, 20)  # bp / nm
persisLength = arange(10, 210, 20) # nm
segConvFactor = 25 / min(persisLength) # segments / min persisLen
nameDB = 'rw_' + dateStr
locPrecision = 2.45 # nm

tic = time.time()
myCollector = WLCCollector(numPaths,
			   pathLength,
			   linDensity,
			   persisLength,
			   segConvFactor,
			   nameDB,
			   locPrecision)
toc = time.time()
print('Total processing time: %f' % (toc - tic))

* rw_2015-1-7
__version__ = '0.5'
Simulate Hela L WT with a medium-resolution of parameters

from numpy import ones, append
kwargs = {}
kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
kwargs['pathLength'] =  13900 * (random(kwargs['numPaths']) - 0.5) + 26250 # bp in walk
#kwargs['pathLength'] = 25000 * ones(kwargs['numPaths'])
kwargs['linDensity'] = arange(20, 70, 10)  # bp / nm
kwargs['persisLength'] = arange(20, 110, 10) # nm
#linDensity = array([100])
#persisLength = array([100])
kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
kwargs['nameDB'] = 'rw_' + dateStr
kwargs['locPrecision'] = 2.12 # nm

tic = time.time()
myCollector = WLCCollector(**kwargs)
toc = time.time()
print('Total processing time: %f' % (toc - tic))
* [#C] rw_2015-1-14_HelaL_WT
  Simulation of Hela L untransfected cells with the Southern blot in
  the paper.

  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = arange(10, 110, 20)  # bp / nm
  kwargs['persisLength'] = arange(10, 210, 20) # nm
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))

* [#C] rw_2015-1-15_HelaS_WT

Simulation of Hela S untransfected cells with the Southern blot in the
paper.

__version__ = '0.5'
from numpy import ones, append
kwargs = {}
kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
kwargs['linDensity'] =arange(10, 110, 20)  # bp / nm
kwargs['persisLength'] = arange(10, 210, 20) # nm
kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
kwargs['nameDB'] = 'rw_' + dateStr
kwargs['locPrecision'] = 2.45 # nm

* [#C] rw_2015-1-15_HelaL_WT
Simulate another section of the parameter grid, zooming in slightly
around the previous Hela L peak.

__version__ = '0.5'
from numpy import ones, append
kwargs = {}
kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
kwargs['linDensity'] = arange(20, 100, 20)  # bp / nm
kwargs['persisLength'] = arange(20, 120, 20) # nm
kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
kwargs['nameDB'] = 'rw_' + dateStr
kwargs['locPrecision'] = 2.12 # nm

* [#C] rw_2015-1-16_HelaL_WT
  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = arange(15, 65, 10)  # bp / nm
  kwargs['persisLength'] = arange(15,105 , 10) # nm 
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* [#C] rw_2015-1-16_HelaS_WT
  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
  #kwargs['pathLength'] = 25000 * ones(kwargs['numPaths'])
  kwargs['linDensity'] = array([5, 15, 20, 25, 35])  # bp / nm
  kwargs['persisLength'] = arange(20, 100, 20) # nm
  #linDensity = array([100])
  #persisLength = array([100])
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.45 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* [#C] rw_2015-1-20_HelaL_WT
  Here I'm checking the upper persistence length range of the Hela L
  WT parameter space.
  
  __version__ = '0.5'
  from numpy import ones, append
  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  #kwargs['pathLength'] = 25000 * ones(kwargs['numPaths'])
  kwargs['linDensity'] = arange(30, 55, 5)  # bp / nm
  kwargs['persisLength'] = arange(100, 210, 10) # nm
  #linDensity = array([100])
  #persisLength = array([100])
  kwargs['segConvFactor'] = 25 / 10 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* [#A] rw_2015-1-26_HelaL_WT
  __version__ = '0.6'
  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 60, 5), arange(10, 105, 5))
  C2, LP2 = meshgrid(arange(30, 65, 5), arange(105, 205, 5))
  C3, LP3 = meshgrid(arange(60, 100, 10), arange(10, 220, 20))
  C4, LP4 = meshgrid(array([20]), arange(110, 210, 20))

  C = concatenate((C1.flatten(), C2.flatten(), C3.flatten(), C4.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten(), LP3.flatten(), LP4.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 10 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* [#A] rw_2015-2-2_HelaS_WT
  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 55, 5), arange(10, 205, 5))
  C2, LP2 = meshgrid(arange(60, 100, 10), arange(10, 205, 20))

  C = concatenate((C1.flatten(), C2.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 10 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))
* [#B] rw_2015-3-7-HelaL_WT
  These are full simulations using the mean localization precision
  from the data.

  __version__ = '0.6'

  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 60, 5), arange(10, 105, 5))
  C2, LP2 = meshgrid(arange(30, 65, 5), arange(105, 205, 5))
  C3, LP3 = meshgrid(arange(60, 100, 10), arange(10, 220, 20))
  C4, LP4 = meshgrid(array([20]), arange(110, 210, 20))

  C = concatenate((C1.flatten(), C2.flatten(), C3.flatten(), C4.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten(), LP3.flatten(), LP4.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  24000 * (random(kwargs['numPaths']) - 0.5) + 27000 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.12 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
  print('Total processing time: %f' % (toc - tic))

* [#B] rw_2015-3-7-HelaS_WT
  These are full simulations using the mean localization precision
  from the data.

  __version__ = '0.6'
  
  from numpy import ones, append, array, concatenate
  C1, LP1 = meshgrid(arange(10, 55, 5), arange(10, 205, 5))
  C2, LP2 = meshgrid(arange(60, 100, 10), arange(10, 205, 20))

  C = concatenate((C1.flatten(), C2.flatten()))
  LP = concatenate((LP1.flatten(), LP2.flatten()))

  kwargs = {}
  kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
  kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
  kwargs['linDensity'] = C  # bp / nm
  kwargs['persisLength'] = LP # nm 
  kwargs['segConvFactor'] = 2.5 # segments / min persisLen
  kwargs['nameDB'] = 'rw_' + dateStr
  kwargs['locPrecision'] = 2.45 # nm
  kwargs['fullSpecParam'] = True

  tic = time.time()
  myCollector = WLCCollector(**kwargs)
  toc = time.time()
* [#C] rw_2015-8-7
  With this I wanted to compare the simulated datasets with 5 nm
  precision to an experimental dataset taken on the HT-STORM
  microscope, which also has a 5 nm precision.
  

 from numpy import ones, append, array, concatenate
 C1, LP1 = meshgrid(arange(10, 55, 5), arange(10, 205, 5))
 C2, LP2 = meshgrid(arange(60, 100, 10), arange(10, 205, 20))

 C = concatenate((C1.flatten(), C2.flatten()))
 LP = concatenate((LP1.flatten(), LP2.flatten()))

 kwargs = {}
 kwargs['numPaths'] = 100000 # Number of paths per pair of walk parameters
 kwargs['pathLength'] =  7000 * (random(kwargs['numPaths']) - 0.5) + 12500 # bp in walk
 kwargs['linDensity'] = C  # bp / nm
 kwargs['persisLength'] = LP # nm
 kwargs['segConvFactor'] = 2.5 # segments / min persisLen
 kwargs['nameDB'] = 'rw_' + dateStr
 kwargs['locPrecision'] = 5 # nm
 kwargs['fullSpecParam'] = True
 
 tic = time.time()
 myCollector = WLCCollector(**kwargs)
 toc = time.time()
 print('Total processing time: %f' % (toc - tic))
